name: Build and Test

on:
  push:
    branches: [ "master", "ci" ]
  pull_request:
    branches: [ "master" ]

env:
  # Customize the CMake build type here (Release, Debug, RelWithDebInfo, etc.)
  BUILD_TYPE: Release
  FR_MODEL_DIR: /tmp/models

jobs:
  build-and-test:
    # The CMake configure and build commands are platform agnostic and should work equally well on Windows or Mac.
    # You can convert this to a matrix build if you need cross-platform coverage.
    # See: https://docs.github.com/en/free-pro-team@latest/actions/learn-github-actions/managing-complex-workflows#using-a-build-matrix
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v3

    - name: Install Ninja
      run: |
        sudo apt-get install ninja-build

    - uses: actions/setup-java@v3
      with:
        distribution: 'zulu'
        java-version: '17'

    - name: Build Android AAR
      run: |
        ./aar/build_aar.sh

    - name: Download ChatRWKV models
      run: |
        mkdir ${{env.FR_MODEL_DIR}}
        cd ${{env.FR_MODEL_DIR}}
        wget https://huggingface.co/BlinkDL/rwkv-4-world/resolve/main/RWKV-4-World-0.1B-v1-20230520-ctx4096.pth 
        wget https://huggingface.co/BlinkDL/rwkv-5-world/resolve/main/RWKV-5-World-0.1B-v1-20230803-ctx4096.pth
    - name: Convert ChatRWKV models
      run: |
        git clone https://github.com/BlinkDL/ChatRWKV
        cd ChatRWKV
        pip install -r requirements.txt
        pip install numpy
        pip install torch --index-url https://download.pytorch.org/whl/cpu
        cd rwkv_pip_package
        pip install .
        cd ..
        python3 v2/convert_model.py --in ${{env.FR_MODEL_DIR}}/RWKV-4-World-0.1B-v1-20230520-ctx4096.pth  --out ${{env.FR_MODEL_DIR}}/RWKV-4-World-0.1B-v1-20230520-ctx4096-fp32-converted.pth --strategy "cuda fp32"
        python3 v2/convert_model.py --in ${{env.FR_MODEL_DIR}}/RWKV-4-World-0.1B-v1-20230520-ctx4096.pth  --out ${{env.FR_MODEL_DIR}}/RWKV-4-World-0.1B-v1-20230520-ctx4096-fp16-converted.pth --strategy "cuda fp16"
        python3 v2/convert_model.py --in ${{env.FR_MODEL_DIR}}/RWKV-5-World-0.1B-v1-20230803-ctx4096.pth  --out ${{env.FR_MODEL_DIR}}/RWKV-5-World-0.1B-v1-20230803-ctx4096-fp32-converted.pth --strategy "cuda fp32"
        cd ..
        pip install -r tools/requirements.txt
        python3 tools/convert_weight.py ${{env.FR_MODEL_DIR}}/RWKV-4-World-0.1B-v1-20230520-ctx4096-fp32-converted.pth ${{env.FR_MODEL_DIR}}/RWKV-4-World-0.1B-v1-20230520-ctx4096-fp32.fr
        python3 tools/convert_weight.py ${{env.FR_MODEL_DIR}}/RWKV-4-World-0.1B-v1-20230520-ctx4096-fp16-converted.pth ${{env.FR_MODEL_DIR}}/RWKV-4-World-0.1B-v1-20230520-ctx4096-fp16.fr
        python3 tools/convert_weight.py ${{env.FR_MODEL_DIR}}/RWKV-5-World-0.1B-v1-20230803-ctx4096-fp32-converted.pth ${{env.FR_MODEL_DIR}}/RWKV-5-World-0.1B-v1-20230803-ctx4096-fp32.fr

    - name: Configure CMake
      run: cmake -B ${{github.workspace}}/build -DCMAKE_BUILD_TYPE=${{env.BUILD_TYPE}} -DFR_ENABLE_NCNN=ON -GNinja

    - name: Build
      run: cmake --build ${{github.workspace}}/build

    - name: Test
      working-directory: ${{github.workspace}}/build
      # Execute tests defined by the CMake configuration.
      # See https://cmake.org/cmake/help/latest/manual/ctest.1.html for more detail
      run: |
        FR_MODEL_DIR=${{env.FR_MODEL_DIR}} ctest -C ${{env.BUILD_TYPE}} -vv --output-on-failure

    - name: Upload Android AAR
      uses: actions/upload-artifact@v3
      with:
        name: Android AAR Packages
        path: aar/java/faster-rwkv-java/build/outputs/aar/*
